{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":18613,"sourceType":"datasetVersion","datasetId":5839}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Dataset Setup and Preprocessing","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport glob\nimport os\n\n# Paths to metadata and image directory\nmetadata_path = '/kaggle/input/data/Data_Entry_2017.csv'\nimages_root_path = '/kaggle/input/data'\n\n# Load the metadata\nmetadata = pd.read_csv(metadata_path)\n\n# Use glob to get a list of all image paths within subfolders like images_001/images\nall_image_paths = glob.glob(os.path.join(images_root_path, 'images_*/images/*.png'))\n\n# Create a dictionary to map each image filename to its full path\nimage_paths_dict = {os.path.basename(path): path for path in all_image_paths}\n\n# Now, add a column in metadata with the full image paths\nmetadata['image_path'] = metadata['Image Index'].map(image_paths_dict)\n\n# Filter out any images that might be missing\nmetadata = metadata.dropna(subset=['image_path'])\n\n# Display the first few rows to verify\nprint(metadata[['Image Index', 'image_path']].head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T18:08:13.923938Z","iopub.execute_input":"2024-11-09T18:08:13.924649Z","iopub.status.idle":"2024-11-09T18:08:22.292863Z","shell.execute_reply.started":"2024-11-09T18:08:13.924610Z","shell.execute_reply":"2024-11-09T18:08:22.291858Z"}},"outputs":[{"name":"stdout","text":"        Image Index                                         image_path\n0  00000001_000.png  /kaggle/input/data/images_001/images/00000001_...\n1  00000001_001.png  /kaggle/input/data/images_001/images/00000001_...\n2  00000001_002.png  /kaggle/input/data/images_001/images/00000001_...\n3  00000002_000.png  /kaggle/input/data/images_001/images/00000002_...\n4  00000003_000.png  /kaggle/input/data/images_001/images/00000003_...\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import tensorflow as tf\n\n# Create a tf.data.Dataset from the image paths\ndef load_and_preprocess_image(image_path):\n    img = tf.io.read_file(image_path)\n    img = tf.image.decode_png(img, channels=3)  # Decode PNG image\n    img = tf.image.resize(img, [224, 224])  # Resize to 224x224 for CNN input\n    img = img / 255.0  # Normalize to [0, 1]\n    return img\n\n# Create a tf.data.Dataset object that processes the images in parallel\nimage_paths = metadata['image_path'].values\n\ndataset = tf.data.Dataset.from_tensor_slices(image_paths)\ndataset = dataset.map(lambda x: load_and_preprocess_image(x), num_parallel_calls=tf.data.AUTOTUNE)\ndataset = dataset.batch(32).prefetch(tf.data.AUTOTUNE)  # Batch and prefetch for better performance\n\n# Check the dataset\nfor batch in dataset.take(1):\n    print(batch.shape)  # Should print (32, 224, 224, 3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T18:08:26.470928Z","iopub.execute_input":"2024-11-09T18:08:26.471804Z","iopub.status.idle":"2024-11-09T18:08:47.490310Z","shell.execute_reply.started":"2024-11-09T18:08:26.471760Z","shell.execute_reply":"2024-11-09T18:08:47.489283Z"}},"outputs":[{"name":"stdout","text":"(32, 224, 224, 3)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# 2. Handling Labels","metadata":{}},{"cell_type":"code","source":"# Example: Convert labels from the metadata (assuming binary labels)\ndef get_labels(metadata):\n    label_map = {'No Finding': 0, 'Disease': 1}  # Map labels to integers\n    labels = metadata['Finding Labels'].map(label_map).values\n    return labels\n\nlabels = get_labels(metadata)\n\nlabels = labels.reshape(-1, 1)\n\n# Create a tf.data.Dataset that yields (image, label) pairs\nlabel_dataset = tf.data.Dataset.from_tensor_slices(labels)\n\n# Zip the image dataset with the label dataset\ndataset = tf.data.Dataset.zip((dataset, label_dataset))\n\n# Now, the dataset will yield tuples of (image, label) batches","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-09T18:08:59.925488Z","iopub.execute_input":"2024-11-09T18:08:59.926121Z","iopub.status.idle":"2024-11-09T18:08:59.952302Z","shell.execute_reply.started":"2024-11-09T18:08:59.926085Z","shell.execute_reply":"2024-11-09T18:08:59.951480Z"}},"outputs":[],"execution_count":4}]}